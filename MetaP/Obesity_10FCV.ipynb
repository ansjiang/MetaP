{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obesity disease prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples are 253 , Raw features are 465 ...\n",
      "filter data after samples are 253 , filter Raw features are 197 ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "disease = \"Obesity\" \n",
    "# feature_string = 'K_' or 'gi_'\n",
    "def loadData(feature_string , label_string , label_dict) :\n",
    "    #read file\n",
    "    \n",
    "    filename = \"./data/abundance_\" + disease + \".txt\"  \n",
    "    if os.path.isfile(filename) :\n",
    "        rawdata = pd.read_csv(filename , sep = '\\t' , index_col=0 , header=None) \n",
    "    else :\n",
    "        print(\"FileNotFoundError: File {} does not exist\".format(filename))\n",
    "        exit()\n",
    "\n",
    "    # select rows having feature index identifier string  \n",
    "    X = rawdata.loc[rawdata.index.str.contains(feature_string, regex=False)].astype('float64')\n",
    "\n",
    "    # get class labels\n",
    "    Y = rawdata.loc[label_string] #'disease'\n",
    "    Y = Y.replace(label_dict).astype('int')\n",
    "     \n",
    "    return X , Y \n",
    "\n",
    "# def prepare_data(config) :\n",
    "feature_string = 'k__'\n",
    "label_string = 'disease'\n",
    "label_dict = {\n",
    "    # Controls\n",
    "    'n': 0,\n",
    "    # Cirrhosis\n",
    "    'cirrhosis': 1, \n",
    "    # T2D and WT2D\n",
    "    't2d': 1,\n",
    "    # Obesity\n",
    "    'leaness': 0, 'obesity': 1,\n",
    "}\n",
    "\n",
    "Raw_X_data , labels = loadData(feature_string , label_string , label_dict )\n",
    "Raw_X_data = Raw_X_data.transpose() \n",
    "labels = labels.values\n",
    "def filter_data(x , y , filter_thresh) :\n",
    "    \n",
    "    classes = np.unique(y) \n",
    "    index = x.index.values  \n",
    "\n",
    "    num_counts = {} \n",
    "    for c in classes :\n",
    "        sub_x = x[y == c]\n",
    "        num_samples = len(sub_x) \n",
    "        # sub_x[sub_x > 0].count()  \n",
    "        num_counts[str(c)] = sub_x[sub_x > 0].count() / float(num_samples)\n",
    "\n",
    "    core = pd.DataFrame(index=index)\n",
    "    for feature in x.columns.values:\n",
    "        for c in classes : \n",
    "            if(num_counts[str(c)].loc[feature] >= filter_thresh) :\n",
    "                #core[feature] = x[feature].copy()\n",
    "                core = pd.concat([core , x[feature]] , axis=1)\n",
    "                break \n",
    "    return core \n",
    "\n",
    "def get_feature_df(features):\n",
    "    kingdom, phylum, cl, order, family, genus, species  = [], [], [], [], [], [], []\n",
    "    for f in features:\n",
    "\n",
    "        name = f.split(\"k__\")[1].split(\"|p__\")[0].replace(\".\",\"\")\n",
    "        if \"_unclassified\" in name:\n",
    "            name = 'unclassified_' + name.split(\"_unclassified\")[0]\n",
    "        kingdom.append(name)\n",
    "\n",
    "        if \"p__\" in f:\n",
    "            name =f.split(\"p__\")[1].split(\"|c__\")[0].replace(\".\",\"\")\n",
    "            if \"_unclassified\" in name:\n",
    "                name = 'unclassified_' + name.split(\"_unclassified\")[0]\n",
    "            if name != \"\":\n",
    "                phylum.append(name)\n",
    "            else:\n",
    "                phylum.append(\"NA\")\n",
    "        else:\n",
    "            phylum.append(\"NA\")\n",
    "            \n",
    "        if \"c__\" in f:\n",
    "            name = f.split(\"c__\")[1].split(\"|o__\")[0].replace(\".\",\"\")\n",
    "            if \"_unclassified\" in name:\n",
    "                name = 'unclassified_' + name.split(\"_unclassified\")[0]\n",
    "            if name != \"\":\n",
    "                cl.append(name)\n",
    "            else:\n",
    "                cl.append(\"NA\")\n",
    "        else:\n",
    "            cl.append(\"NA\")\n",
    "            \n",
    "        if \"o__\" in f:\n",
    "            name = f.split(\"o__\")[1].split(\"|f__\")[0].replace(\".\",\"\")\n",
    "            if \"_unclassified\" in name:\n",
    "                name = 'unclassified_' + name.split(\"_unclassified\")[0]\n",
    "            if name != \"\":\n",
    "                order.append(name)\n",
    "            else:\n",
    "                order.append(\"NA\")\n",
    "        else:\n",
    "            order.append(\"NA\")\n",
    "            \n",
    "        if \"f__\" in f:\n",
    "            name = f.split(\"f__\")[1].split(\"|g__\")[0].replace(\".\",\"\")\n",
    "            if \"_unclassified\" in name:\n",
    "                name = 'unclassified_' + name.split(\"_unclassified\")[0]\n",
    "            if name != \"\":\n",
    "                family.append(name)\n",
    "            else:\n",
    "                family.append(\"NA\")\n",
    "        else:\n",
    "            family.append(\"NA\")\n",
    "            \n",
    "        if \"g__\" in f:\n",
    "            name = f.split(\"g__\")[1].split(\"|s__\")[0].replace(\".\",\"\")\n",
    "            if \"_unclassified\" in name:\n",
    "                name = 'unclassified_' + name.split(\"_unclassified\")[0]\n",
    "            if name != \"\":\n",
    "                genus.append(name)\n",
    "            else:\n",
    "                genus.append(\"NA\")\n",
    "        else:\n",
    "            genus.append(\"NA\")\n",
    "            \n",
    "        if \"s__\" in f:\n",
    "            name = f.split(\"s__\")[1]\n",
    "            if \"_unclassified\" in name:\n",
    "                name = 'unclassified_' + name.split(\"_unclassified\")[0]\n",
    "            if name != \"\":\n",
    "                species.append(name)\n",
    "            else:\n",
    "                species.append(\"NA\")\n",
    "        else:\n",
    "            species.append(\"NA\")\n",
    "            \n",
    "    if len(species) == 0:\n",
    "        d = {'kingdom': kingdom, 'phylum': phylum, 'class':cl,\n",
    "            'order':order, 'family':family, 'genus':genus}\n",
    "        feature_df = pd.DataFrame(data=d)\n",
    "        feature_df.index = feature_df['genus']\n",
    "    else:\n",
    "        d = {'kingdom': kingdom, 'phylum': phylum, 'class':cl,\n",
    "            'order':order, 'family':family, 'genus':genus, 'species': species}\n",
    "        feature_df = pd.DataFrame(data=d)\n",
    "        feature_df.index = feature_df['species']\n",
    "    return feature_df\n",
    " \n",
    "filter_X_data = filter_data(Raw_X_data , labels , 0.1)\n",
    "features = list(filter_X_data.columns.values)\n",
    "features_df = get_feature_df(features)  \n",
    "print(\"samples are %d , Raw features are %d ...\" % (Raw_X_data.shape[0] ,  Raw_X_data.shape[1]))  \n",
    "print(\"filter data after samples are %d , filter Raw features are %d ...\" % (filter_X_data.shape[0] ,  filter_X_data.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "classes = set(labels)\n",
    "for c in classes:\n",
    "    print(list(labels).count(c)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contsructing tree..\n",
      "Pruning Tree...\n",
      "Populating trees...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\70923\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 13, 141)\n",
      "(253, 8, 141)\n",
      "(253, 197)\n"
     ]
    }
   ],
   "source": [
    "from graph import Graph\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from copy import deepcopy\n",
    "\n",
    "#Convert abundance vector into tree matrix\n",
    "def generate_maps(x, g, f, p=-1):\n",
    "\tid = multiprocessing.Process()._identity\n",
    "\ttemp_g = deepcopy(g)\n",
    "\ttemp_g.populate_graph(f, x)\n",
    "\tmap = temp_g.get_map()\n",
    "\tvector = temp_g.graph_vector_features()\n",
    "\tdel(temp_g)\n",
    "\treturn x, np.array(map), np.array(vector)\n",
    "\n",
    "def generate_dense_maps(x, g, f, p=-1):\n",
    "    id = multiprocessing.Process()._identity\n",
    "    temp_g = deepcopy(g)\n",
    "    temp_g.populate_graph(f, x)\n",
    "    map = temp_g.get_dense_map()\n",
    "    vector = temp_g.graph_vector_features()\n",
    "    del(temp_g)\n",
    "    return np.array(map)\n",
    "\n",
    "print(\"Contsructing tree..\")\n",
    "g = Graph()\n",
    "g.build_graph()\n",
    "g.prune_graph(features_df)\n",
    "print(\"Populating trees...\")\t\n",
    "results1 = Parallel(n_jobs=1)(delayed(generate_maps)(x,g,features_df) for x in filter_X_data.values)\n",
    "x_data_sparse_maps = np.array(np.take(results1,1,1).tolist()) \n",
    "results2 = Parallel(n_jobs=4)(delayed(generate_dense_maps)(x,g,features_df) for x in filter_X_data.values)\n",
    "x_data_dense_maps = np.array(results2) \n",
    "filter_x_data = filter_X_data.values \n",
    "\n",
    "print(x_data_sparse_maps.shape)\n",
    "print(x_data_dense_maps.shape)\n",
    "print(filter_x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10\n",
    "num_test = 10 \n",
    "num_class = len(np.unique(labels))  \n",
    "\n",
    "seed = np.random.randint(100)  \n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(x_data_sparse_maps)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(x_data_dense_maps)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(filter_x_data) \n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "n_values = np.max(labels) + 1\n",
    "labels_oh = np.eye(n_values)[labels]\n",
    "seeds = [8, 16, 32, 64, 128, 256, 1024, 2048, 4096, 8192]  \n",
    "\n",
    "cv_list = [\"Run_\" + str(x) + \"_CV_\" + str(y) for x in range(num_runs) for y in range(num_test)]\n",
    "MetaP_stat_df = pd.DataFrame(index=[\"AUC\", \"ACC\" , \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=cv_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 10 CV\n",
      "################################################## repeat_seed: 8; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 0 , metrics {'ACC': 0.615, 'Recall': 0.615, 'Precision': 0.542, 'F1': 0.548, 'MCC': -0.01, 'AUC': 0.588, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 1 , metrics {'ACC': 0.654, 'Recall': 0.654, 'Precision': 0.619, 'F1': 0.609, 'MCC': 0.138, 'AUC': 0.686, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 2 , metrics {'ACC': 0.577, 'Recall': 0.577, 'Precision': 0.54, 'F1': 0.552, 'MCC': -0.015, 'AUC': 0.542, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 3 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.604, 'F1': 0.613, 'MCC': 0.086, 'AUC': 0.529, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 4 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.597, 'F1': 0.558, 'MCC': 0.086, 'AUC': 0.569, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 5 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.607, 'F1': 0.595, 'MCC': 0.127, 'AUC': 0.66, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 6 , metrics {'ACC': 0.68, 'Recall': 0.68, 'Precision': 0.664, 'F1': 0.652, 'MCC': 0.25, 'AUC': 0.639, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 7 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.618, 'F1': 0.619, 'MCC': 0.164, 'AUC': 0.688, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 8 , metrics {'ACC': 0.72, 'Recall': 0.72, 'Precision': 0.712, 'F1': 0.704, 'MCC': 0.359, 'AUC': 0.764, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 9 , metrics {'ACC': 0.76, 'Recall': 0.76, 'Precision': 0.755, 'F1': 0.752, 'MCC': 0.46, 'AUC': 0.819, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 0 , metrics {'ACC': 0.538, 'Recall': 0.538, 'Precision': 0.538, 'F1': 0.538, 'MCC': -0.02, 'AUC': 0.542, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 1 , metrics {'ACC': 0.692, 'Recall': 0.692, 'Precision': 0.68, 'F1': 0.682, 'MCC': 0.287, 'AUC': 0.719, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 2 , metrics {'ACC': 0.577, 'Recall': 0.577, 'Precision': 0.409, 'F1': 0.478, 'MCC': -0.21, 'AUC': 0.569, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 3 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.628, 'F1': 0.633, 'MCC': 0.145, 'AUC': 0.632, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 4 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.581, 'F1': 0.587, 'MCC': 0.089, 'AUC': 0.653, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 5 , metrics {'ACC': 0.68, 'Recall': 0.68, 'Precision': 0.668, 'F1': 0.669, 'MCC': 0.275, 'AUC': 0.729, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 6 , metrics {'ACC': 0.68, 'Recall': 0.68, 'Precision': 0.664, 'F1': 0.652, 'MCC': 0.25, 'AUC': 0.715, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 7 , metrics {'ACC': 0.84, 'Recall': 0.84, 'Precision': 0.872, 'F1': 0.826, 'MCC': 0.667, 'AUC': 0.757, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 8 , metrics {'ACC': 0.68, 'Recall': 0.68, 'Precision': 0.664, 'F1': 0.652, 'MCC': 0.25, 'AUC': 0.729, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 9 , metrics {'ACC': 0.52, 'Recall': 0.52, 'Precision': 0.456, 'F1': 0.478, 'MCC': -0.167, 'AUC': 0.438, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 0 , metrics {'ACC': 0.654, 'Recall': 0.654, 'Precision': 0.619, 'F1': 0.609, 'MCC': 0.138, 'AUC': 0.627, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 1 , metrics {'ACC': 0.692, 'Recall': 0.692, 'Precision': 0.68, 'F1': 0.682, 'MCC': 0.287, 'AUC': 0.719, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 2 , metrics {'ACC': 0.731, 'Recall': 0.731, 'Precision': 0.735, 'F1': 0.696, 'MCC': 0.362, 'AUC': 0.797, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 3 , metrics {'ACC': 0.56, 'Recall': 0.56, 'Precision': 0.574, 'F1': 0.566, 'MCC': 0.021, 'AUC': 0.61, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 4 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.597, 'F1': 0.558, 'MCC': 0.086, 'AUC': 0.674, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 5 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.607, 'F1': 0.595, 'MCC': 0.127, 'AUC': 0.674, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 6 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.581, 'F1': 0.587, 'MCC': 0.089, 'AUC': 0.611, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 7 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.4, 'F1': 0.48, 'MCC': -0.153, 'AUC': 0.729, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 8 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.597, 'F1': 0.558, 'MCC': 0.086, 'AUC': 0.569, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 9 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.618, 'F1': 0.619, 'MCC': 0.164, 'AUC': 0.618, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 0 , metrics {'ACC': 0.808, 'Recall': 0.808, 'Precision': 0.814, 'F1': 0.81, 'MCC': 0.588, 'AUC': 0.882, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 1 , metrics {'ACC': 0.538, 'Recall': 0.538, 'Precision': 0.398, 'F1': 0.458, 'MCC': -0.263, 'AUC': 0.523, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 2 , metrics {'ACC': 0.654, 'Recall': 0.654, 'Precision': 0.609, 'F1': 0.573, 'MCC': 0.093, 'AUC': 0.477, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 3 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.57, 'F1': 0.581, 'MCC': 0.011, 'AUC': 0.64, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 4 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.597, 'F1': 0.558, 'MCC': 0.086, 'AUC': 0.611, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 5 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.581, 'F1': 0.587, 'MCC': 0.089, 'AUC': 0.611, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 6 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.6, 'F1': 0.6, 'MCC': 0.132, 'AUC': 0.681, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 7 , metrics {'ACC': 0.8, 'Recall': 0.8, 'Precision': 0.848, 'F1': 0.775, 'MCC': 0.582, 'AUC': 0.757, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 8 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.632, 'F1': 0.635, 'MCC': 0.2, 'AUC': 0.639, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 9 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.56, 'F1': 0.565, 'MCC': 0.042, 'AUC': 0.639, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 0 , metrics {'ACC': 0.808, 'Recall': 0.808, 'Precision': 0.812, 'F1': 0.796, 'MCC': 0.561, 'AUC': 0.784, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 1 , metrics {'ACC': 0.654, 'Recall': 0.654, 'Precision': 0.619, 'F1': 0.609, 'MCC': 0.138, 'AUC': 0.641, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 2 , metrics {'ACC': 0.615, 'Recall': 0.615, 'Precision': 0.418, 'F1': 0.498, 'MCC': -0.146, 'AUC': 0.647, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 3 , metrics {'ACC': 0.56, 'Recall': 0.56, 'Precision': 0.602, 'F1': 0.573, 'MCC': 0.083, 'AUC': 0.625, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 4 , metrics {'ACC': 0.48, 'Recall': 0.48, 'Precision': 0.466, 'F1': 0.473, 'MCC': -0.157, 'AUC': 0.535, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 5 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.56, 'F1': 0.565, 'MCC': 0.042, 'AUC': 0.597, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 6 , metrics {'ACC': 0.72, 'Recall': 0.72, 'Precision': 0.714, 'F1': 0.716, 'MCC': 0.379, 'AUC': 0.708, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 7 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.607, 'F1': 0.595, 'MCC': 0.127, 'AUC': 0.535, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 8 , metrics {'ACC': 0.44, 'Recall': 0.44, 'Precision': 0.352, 'F1': 0.391, 'MCC': -0.375, 'AUC': 0.59, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 9 , metrics {'ACC': 0.84, 'Recall': 0.84, 'Precision': 0.872, 'F1': 0.826, 'MCC': 0.667, 'AUC': 0.931, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 0 , metrics {'ACC': 0.769, 'Recall': 0.769, 'Precision': 0.775, 'F1': 0.748, 'MCC': 0.465, 'AUC': 0.712, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 1 , metrics {'ACC': 0.538, 'Recall': 0.538, 'Precision': 0.562, 'F1': 0.547, 'MCC': 0.031, 'AUC': 0.523, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 2 , metrics {'ACC': 0.577, 'Recall': 0.577, 'Precision': 0.409, 'F1': 0.478, 'MCC': -0.21, 'AUC': 0.608, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 3 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.572, 'F1': 0.583, 'MCC': 0.016, 'AUC': 0.706, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 4 , metrics {'ACC': 0.8, 'Recall': 0.8, 'Precision': 0.848, 'F1': 0.775, 'MCC': 0.582, 'AUC': 0.743, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 5 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.56, 'F1': 0.565, 'MCC': 0.042, 'AUC': 0.694, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 6 , metrics {'ACC': 0.68, 'Recall': 0.68, 'Precision': 0.664, 'F1': 0.652, 'MCC': 0.25, 'AUC': 0.826, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 7 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.618, 'F1': 0.619, 'MCC': 0.164, 'AUC': 0.611, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 8 , metrics {'ACC': 0.52, 'Recall': 0.52, 'Precision': 0.494, 'F1': 0.504, 'MCC': -0.097, 'AUC': 0.479, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 9 , metrics {'ACC': 0.76, 'Recall': 0.76, 'Precision': 0.768, 'F1': 0.739, 'MCC': 0.458, 'AUC': 0.924, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 0 , metrics {'ACC': 0.5, 'Recall': 0.5, 'Precision': 0.512, 'F1': 0.506, 'MCC': -0.077, 'AUC': 0.588, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 1 , metrics {'ACC': 0.692, 'Recall': 0.692, 'Precision': 0.686, 'F1': 0.638, 'MCC': 0.243, 'AUC': 0.81, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 2 , metrics {'ACC': 0.692, 'Recall': 0.692, 'Precision': 0.68, 'F1': 0.682, 'MCC': 0.287, 'AUC': 0.686, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 3 , metrics {'ACC': 0.72, 'Recall': 0.72, 'Precision': 0.702, 'F1': 0.699, 'MCC': 0.3, 'AUC': 0.684, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 4 , metrics {'ACC': 0.72, 'Recall': 0.72, 'Precision': 0.727, 'F1': 0.685, 'MCC': 0.355, 'AUC': 0.646, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 5 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.607, 'F1': 0.595, 'MCC': 0.127, 'AUC': 0.66, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 6 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.4, 'F1': 0.48, 'MCC': -0.153, 'AUC': 0.715, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 7 , metrics {'ACC': 0.76, 'Recall': 0.76, 'Precision': 0.825, 'F1': 0.719, 'MCC': 0.492, 'AUC': 0.722, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 8 , metrics {'ACC': 0.68, 'Recall': 0.68, 'Precision': 0.676, 'F1': 0.625, 'MCC': 0.236, 'AUC': 0.549, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 9 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.581, 'F1': 0.587, 'MCC': 0.089, 'AUC': 0.715, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 0 , metrics {'ACC': 0.654, 'Recall': 0.654, 'Precision': 0.631, 'F1': 0.633, 'MCC': 0.177, 'AUC': 0.667, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 1 , metrics {'ACC': 0.808, 'Recall': 0.808, 'Precision': 0.814, 'F1': 0.81, 'MCC': 0.588, 'AUC': 0.817, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 2 , metrics {'ACC': 0.769, 'Recall': 0.769, 'Precision': 0.763, 'F1': 0.761, 'MCC': 0.47, 'AUC': 0.81, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 3 , metrics {'ACC': 0.68, 'Recall': 0.68, 'Precision': 0.68, 'F1': 0.68, 'MCC': 0.265, 'AUC': 0.721, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 4 , metrics {'ACC': 0.56, 'Recall': 0.56, 'Precision': 0.524, 'F1': 0.535, 'MCC': -0.031, 'AUC': 0.632, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 5 , metrics {'ACC': 0.72, 'Recall': 0.72, 'Precision': 0.805, 'F1': 0.656, 'MCC': 0.393, 'AUC': 0.681, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 6 , metrics {'ACC': 0.56, 'Recall': 0.56, 'Precision': 0.39, 'F1': 0.459, 'MCC': -0.221, 'AUC': 0.431, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 7 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.632, 'F1': 0.635, 'MCC': 0.2, 'AUC': 0.625, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 8 , metrics {'ACC': 0.52, 'Recall': 0.52, 'Precision': 0.494, 'F1': 0.504, 'MCC': -0.097, 'AUC': 0.569, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 9 , metrics {'ACC': 0.68, 'Recall': 0.68, 'Precision': 0.676, 'F1': 0.625, 'MCC': 0.236, 'AUC': 0.757, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 0 , metrics {'ACC': 0.615, 'Recall': 0.615, 'Precision': 0.542, 'F1': 0.548, 'MCC': -0.01, 'AUC': 0.739, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 1 , metrics {'ACC': 0.731, 'Recall': 0.731, 'Precision': 0.735, 'F1': 0.696, 'MCC': 0.362, 'AUC': 0.627, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 2 , metrics {'ACC': 0.692, 'Recall': 0.692, 'Precision': 0.675, 'F1': 0.665, 'MCC': 0.26, 'AUC': 0.595, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 3 , metrics {'ACC': 0.52, 'Recall': 0.52, 'Precision': 0.483, 'F1': 0.499, 'MCC': -0.185, 'AUC': 0.522, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 4 , metrics {'ACC': 0.72, 'Recall': 0.72, 'Precision': 0.805, 'F1': 0.656, 'MCC': 0.393, 'AUC': 0.597, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 5 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.632, 'F1': 0.635, 'MCC': 0.2, 'AUC': 0.562, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 6 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.618, 'F1': 0.619, 'MCC': 0.164, 'AUC': 0.819, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 7 , metrics {'ACC': 0.72, 'Recall': 0.72, 'Precision': 0.712, 'F1': 0.704, 'MCC': 0.359, 'AUC': 0.812, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 8 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.581, 'F1': 0.587, 'MCC': 0.089, 'AUC': 0.507, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 9 , metrics {'ACC': 0.64, 'Recall': 0.64, 'Precision': 0.618, 'F1': 0.619, 'MCC': 0.164, 'AUC': 0.729, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 0 , metrics {'ACC': 0.654, 'Recall': 0.654, 'Precision': 0.619, 'F1': 0.609, 'MCC': 0.138, 'AUC': 0.686, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 1 , metrics {'ACC': 0.615, 'Recall': 0.615, 'Precision': 0.596, 'F1': 0.602, 'MCC': 0.105, 'AUC': 0.588, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 2 , metrics {'ACC': 0.808, 'Recall': 0.808, 'Precision': 0.851, 'F1': 0.783, 'MCC': 0.586, 'AUC': 0.778, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 3 , metrics {'ACC': 0.76, 'Recall': 0.76, 'Precision': 0.75, 'F1': 0.75, 'MCC': 0.418, 'AUC': 0.728, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 4 , metrics {'ACC': 0.68, 'Recall': 0.68, 'Precision': 0.676, 'F1': 0.625, 'MCC': 0.236, 'AUC': 0.688, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 5 , metrics {'ACC': 0.68, 'Recall': 0.68, 'Precision': 0.664, 'F1': 0.652, 'MCC': 0.25, 'AUC': 0.667, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 6 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.56, 'F1': 0.565, 'MCC': 0.042, 'AUC': 0.674, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 7 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.581, 'F1': 0.587, 'MCC': 0.089, 'AUC': 0.75, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 8 , metrics {'ACC': 0.68, 'Recall': 0.68, 'Precision': 0.676, 'F1': 0.625, 'MCC': 0.236, 'AUC': 0.722, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 9 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.581, 'F1': 0.587, 'MCC': 0.089, 'AUC': 0.611, 'repeat_seed': 8192, 'method': 'Meta_P'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score ,accuracy_score , matthews_corrcoef, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from MetaP import MetaP  \n",
    "import torch\n",
    " \n",
    "\n",
    "print(\"Starting 10 CV\")\n",
    "for i , repeat_seed in enumerate(seeds) : \n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=repeat_seed)\n",
    "    skf_index = skf.split(x_data_dense_maps, labels) \n",
    "    \n",
    "    for j , idx in enumerate(skf_index) :\n",
    "        fold_num = \"fold_%s\" % str(j).zfill(2)\n",
    "        print('#'*50 + ' repeat_seed: %s; %s ' % (repeat_seed, fold_num) + '#'*50 )\n",
    "\n",
    "        train_index, test_index = idx    \n",
    "        train_x, test_x = x_data_dense_maps[train_index], x_data_dense_maps[test_index]\n",
    "        #train_y, test_y = labels_oh[train_index], labels_oh[test_index]\n",
    "        train_y, test_y = labels[train_index], labels[test_index]\n",
    "\n",
    "        tree_row = train_x.shape[1]\n",
    "        tree_col = train_x.shape[2]\n",
    "        scaler = MinMaxScaler().fit(train_x.reshape(-1, tree_row * tree_col))\n",
    "        train_x = np.clip(scaler.transform(train_x.reshape(-1, tree_row * tree_col)), 0, 1).reshape(-1, tree_row, tree_col)\n",
    "        test_x = np.clip(scaler.transform(test_x.reshape(-1, tree_row * tree_col)), 0, 1).reshape(-1, tree_row, tree_col)\n",
    "\n",
    "        class DatasetLoarder(Dataset) :\n",
    "            def __init__(self , X_train , y_train) :\n",
    "                self.len = X_train.shape[0]\n",
    "                self.x_data = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "                self.y_data = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "                \n",
    "            def __getitem__(self , index) :\n",
    "                return self.x_data[index] , self.y_data[index]\n",
    "\n",
    "            def __len__(self) :\n",
    "                return self.len \n",
    "\n",
    "        train_dataset  = DatasetLoarder(train_x , train_y)  \n",
    "        train_loader = DataLoader(dataset=train_dataset , batch_size=32 , num_workers=0) # num_workers \n",
    "        test_dataset = DatasetLoarder(test_x , test_y)\n",
    "        test_loader = DataLoader(dataset=test_dataset , batch_size=32 , num_workers=0 ) # num_workers \n",
    "                \n",
    "                \n",
    "        def eval(model , test_loader): # test\n",
    "            # loss function\n",
    "            #criterion = torch.nn.CrossEntropyLoss()\n",
    "            model.eval()\n",
    "            true_label = [] \n",
    "            y_prob = []\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for step , batch in enumerate(test_loader):\n",
    "                    x, label = batch\n",
    "                    \n",
    "                    val_output = model(x)\n",
    "                    #val_loss = criterion(val_output, label)\n",
    "                    \n",
    "                    true_label  = true_label + label.tolist() \n",
    "                    y_prob = y_prob + val_output.tolist()\n",
    "                    \n",
    "            y_prob = np.array(y_prob)\n",
    "            true_label = np.array(true_label)\n",
    "            return true_label , y_prob \n",
    "\n",
    "        def train(model , train_loader , test_loader , learn_rate , epoch ) :\n",
    "            \n",
    "            # loss function\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "            # optimizer\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate ) # 5e-4 \n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5 , gamma=0.5)\n",
    "            \n",
    "            for i in range(epoch):\n",
    "                model.train()\n",
    "                # one epoch\n",
    "                for step, batch in enumerate(train_loader):\n",
    "                    x, label = batch\n",
    "                    output = model(x)\n",
    "                    loss = criterion(output, label)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                scheduler.step()\n",
    "                # y_true , y_prob  = eval(model=model , test_loader=test_loader) \n",
    "                # y_pred = np.argmax(y_prob , axis=1)\n",
    "                # #print(\"method = {}  test Epoch:{} ,   eval_acc:{} , eval_auc :{} \".format(method , i, round(accuracy_score(y_true, y_pred), 3) , round(roc_auc_score(y_true, y_prob, multi_class='ovo'), 3)))\n",
    "                # print(\"method = {}  test Epoch:{} ,  eval_acc:{} \".format(\"method\" , i, round(accuracy_score(y_true, y_pred), 3)))\n",
    "\n",
    "                 \n",
    "        model = MetaP(\n",
    "            image_h= train_x.shape[1],\n",
    "            image_w= train_x.shape[2],\n",
    "            segments = 8,\n",
    "            patch_h = train_x.shape[1] ,\n",
    "            patch_w = 3 ,\n",
    "            dim = 48,\n",
    "            depth = 1,\n",
    "            num_classes = 2 ,\n",
    "            expansion_factor = 1, \n",
    "        )\n",
    "        print(\"training........ Micro Permutator model ................. \")\n",
    "\n",
    "        train(model  , train_loader , test_loader , learn_rate=5e-4 , epoch=20)\n",
    "        \n",
    "        y_true , y_prob  = eval(model=model , test_loader=test_loader) \n",
    "        y_pred = np.argmax(y_prob , axis=1)\n",
    "       \n",
    "       \n",
    "        metrics = {   \n",
    "            \"ACC\" : round(accuracy_score(y_true, y_pred), 3),\n",
    "            \"Recall\" : round(recall_score(y_true, y_pred, average='weighted') , 3) ,\n",
    "            \"Precision\" : round(precision_score(y_true, y_pred, average='weighted') , 3) ,\n",
    "            \"F1\"    : round(f1_score(y_true, y_pred, average='weighted') , 3) , \n",
    "            \"MCC\" : round(matthews_corrcoef(y_true, y_pred), 3),\n",
    "            \"AUC\" : round(roc_auc_score(y_true, y_prob[:, 1]) , 3) ,\n",
    "            \"repeat_seed\" : repeat_seed ,  \n",
    "            \"method\" : \"Meta_P\",\n",
    "            } \n",
    "        \n",
    "        print(\"MetaP run {} ,  fold {} , metrics {}\".format(i , j , metrics))\n",
    "\n",
    "        MetaP_stat_df.loc[\"AUC\"][\"Run_\" + str(i) + \"_CV_\" + str(j)] = metrics[\"AUC\"]\n",
    "        MetaP_stat_df.loc[\"ACC\"][\"Run_\" + str(i) + \"_CV_\" + str(j)] = metrics[\"ACC\"]\n",
    "        MetaP_stat_df.loc[\"MCC\"][\"Run_\" + str(i) + \"_CV_\" + str(j)] = metrics[\"MCC\"]\n",
    "        MetaP_stat_df.loc[\"Precision\"][\"Run_\" + str(i) + \"_CV_\" + str(j)] =  metrics[\"Precision\"]\n",
    "        MetaP_stat_df.loc[\"Recall\"][\"Run_\" + str(i) + \"_CV_\" + str(j)]= metrics[\"Recall\"]\n",
    "        MetaP_stat_df.loc[\"F1\"][\"Run_\" + str(i) + \"_CV_\" + str(j)] =  metrics[\"F1\"]\n",
    "\n",
    "        del(model) \n",
    "    #     break\n",
    "    # break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC          0.66360\n",
      "ACC          0.65161\n",
      "MCC          0.16862\n",
      "Precision    0.62687\n",
      "Recall       0.65161\n",
      "F1           0.61868\n",
      "dtype: float64\n",
      "AUC          0.099241\n",
      "ACC          0.081226\n",
      "MCC          0.218192\n",
      "Precision    0.114980\n",
      "Recall       0.081226\n",
      "F1           0.090442\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# results_dir = \"./results/\" + disease\n",
    "# MetaP_stat_df.mean(1).to_csv(results_dir + \"/MetaP_Half_evaluation.csv\")\n",
    "# MetaP_stat_df.std(1).to_csv(results_dir + \"/MetaP_Half_evaluation.csv\", mode='a')\n",
    "\n",
    "print(MetaP_stat_df.mean(1))\n",
    "print(MetaP_stat_df.std(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1976153ee4400fa378d70e78b886b43c01301f7b206e70b97b5161f60de6d8c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
