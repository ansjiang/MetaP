{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T2D disease prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples are 344 , Raw features are 572 ...\n",
      "filter data after samples are 344 , filter Raw features are 225 ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "disease = \"T2D\" \n",
    "# feature_string = 'K_' or 'gi_'\n",
    "def loadData(feature_string , label_string , label_dict) :\n",
    "    #read file\n",
    "    \n",
    "    filename = \"./data/abundance_\" + disease + \".txt\"  \n",
    "    if os.path.isfile(filename) :\n",
    "        rawdata = pd.read_csv(filename , sep = '\\t' , index_col=0 , header=None) \n",
    "    else :\n",
    "        print(\"FileNotFoundError: File {} does not exist\".format(filename))\n",
    "        exit()\n",
    "\n",
    "    # select rows having feature index identifier string  \n",
    "    X = rawdata.loc[rawdata.index.str.contains(feature_string, regex=False)].astype('float64')\n",
    "\n",
    "    # get class labels\n",
    "    Y = rawdata.loc[label_string] #'disease'\n",
    "    Y = Y.replace(label_dict).astype('int')\n",
    "     \n",
    "    return X , Y \n",
    "\n",
    "# def prepare_data(config) :\n",
    "feature_string = 'k__'\n",
    "label_string = 'disease'\n",
    "label_dict = {\n",
    "    # Controls\n",
    "    'n': 0,\n",
    "    # Cirrhosis\n",
    "    'cirrhosis': 1, \n",
    "    # T2D and WT2D\n",
    "    't2d': 1,\n",
    "    # Obesity\n",
    "    'leaness': 0, 'obesity': 1,\n",
    "}\n",
    "\n",
    "Raw_X_data , labels = loadData(feature_string , label_string , label_dict )\n",
    "Raw_X_data = Raw_X_data.transpose() \n",
    "labels = labels.values\n",
    "def filter_data(x , y , filter_thresh) :\n",
    "    \n",
    "    classes = np.unique(y) \n",
    "    index = x.index.values  \n",
    "\n",
    "    num_counts = {} \n",
    "    for c in classes :\n",
    "        sub_x = x[y == c]\n",
    "        num_samples = len(sub_x) \n",
    "        # sub_x[sub_x > 0].count()  \n",
    "        num_counts[str(c)] = sub_x[sub_x > 0].count() / float(num_samples)\n",
    "\n",
    "    core = pd.DataFrame(index=index)\n",
    "    for feature in x.columns.values:\n",
    "        for c in classes : \n",
    "            if(num_counts[str(c)].loc[feature] >= filter_thresh) :\n",
    "                #core[feature] = x[feature].copy()\n",
    "                core = pd.concat([core , x[feature]] , axis=1)\n",
    "                break \n",
    "    return core \n",
    "\n",
    "def get_feature_df(features):\n",
    "    kingdom, phylum, cl, order, family, genus, species  = [], [], [], [], [], [], []\n",
    "    for f in features:\n",
    "\n",
    "        name = f.split(\"k__\")[1].split(\"|p__\")[0].replace(\".\",\"\")\n",
    "        if \"_unclassified\" in name:\n",
    "            name = 'unclassified_' + name.split(\"_unclassified\")[0]\n",
    "        kingdom.append(name)\n",
    "\n",
    "        if \"p__\" in f:\n",
    "            name =f.split(\"p__\")[1].split(\"|c__\")[0].replace(\".\",\"\")\n",
    "            if \"_unclassified\" in name:\n",
    "                name = 'unclassified_' + name.split(\"_unclassified\")[0]\n",
    "            if name != \"\":\n",
    "                phylum.append(name)\n",
    "            else:\n",
    "                phylum.append(\"NA\")\n",
    "        else:\n",
    "            phylum.append(\"NA\")\n",
    "            \n",
    "        if \"c__\" in f:\n",
    "            name = f.split(\"c__\")[1].split(\"|o__\")[0].replace(\".\",\"\")\n",
    "            if \"_unclassified\" in name:\n",
    "                name = 'unclassified_' + name.split(\"_unclassified\")[0]\n",
    "            if name != \"\":\n",
    "                cl.append(name)\n",
    "            else:\n",
    "                cl.append(\"NA\")\n",
    "        else:\n",
    "            cl.append(\"NA\")\n",
    "            \n",
    "        if \"o__\" in f:\n",
    "            name = f.split(\"o__\")[1].split(\"|f__\")[0].replace(\".\",\"\")\n",
    "            if \"_unclassified\" in name:\n",
    "                name = 'unclassified_' + name.split(\"_unclassified\")[0]\n",
    "            if name != \"\":\n",
    "                order.append(name)\n",
    "            else:\n",
    "                order.append(\"NA\")\n",
    "        else:\n",
    "            order.append(\"NA\")\n",
    "            \n",
    "        if \"f__\" in f:\n",
    "            name = f.split(\"f__\")[1].split(\"|g__\")[0].replace(\".\",\"\")\n",
    "            if \"_unclassified\" in name:\n",
    "                name = 'unclassified_' + name.split(\"_unclassified\")[0]\n",
    "            if name != \"\":\n",
    "                family.append(name)\n",
    "            else:\n",
    "                family.append(\"NA\")\n",
    "        else:\n",
    "            family.append(\"NA\")\n",
    "            \n",
    "        if \"g__\" in f:\n",
    "            name = f.split(\"g__\")[1].split(\"|s__\")[0].replace(\".\",\"\")\n",
    "            if \"_unclassified\" in name:\n",
    "                name = 'unclassified_' + name.split(\"_unclassified\")[0]\n",
    "            if name != \"\":\n",
    "                genus.append(name)\n",
    "            else:\n",
    "                genus.append(\"NA\")\n",
    "        else:\n",
    "            genus.append(\"NA\")\n",
    "            \n",
    "        if \"s__\" in f:\n",
    "            name = f.split(\"s__\")[1]\n",
    "            if \"_unclassified\" in name:\n",
    "                name = 'unclassified_' + name.split(\"_unclassified\")[0]\n",
    "            if name != \"\":\n",
    "                species.append(name)\n",
    "            else:\n",
    "                species.append(\"NA\")\n",
    "        else:\n",
    "            species.append(\"NA\")\n",
    "            \n",
    "    if len(species) == 0:\n",
    "        d = {'kingdom': kingdom, 'phylum': phylum, 'class':cl,\n",
    "            'order':order, 'family':family, 'genus':genus}\n",
    "        feature_df = pd.DataFrame(data=d)\n",
    "        feature_df.index = feature_df['genus']\n",
    "    else:\n",
    "        d = {'kingdom': kingdom, 'phylum': phylum, 'class':cl,\n",
    "            'order':order, 'family':family, 'genus':genus, 'species': species}\n",
    "        feature_df = pd.DataFrame(data=d)\n",
    "        feature_df.index = feature_df['species']\n",
    "    return feature_df\n",
    " \n",
    "filter_X_data = filter_data(Raw_X_data , labels , 0.1)\n",
    "features = list(filter_X_data.columns.values)\n",
    "features_df = get_feature_df(features)  \n",
    "print(\"samples are %d , Raw features are %d ...\" % (Raw_X_data.shape[0] ,  Raw_X_data.shape[1]))  \n",
    "print(\"filter data after samples are %d , filter Raw features are %d ...\" % (filter_X_data.shape[0] ,  filter_X_data.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "classes = set(labels)\n",
    "for c in classes:\n",
    "    print(list(labels).count(c)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contsructing tree..\n",
      "Pruning Tree...\n",
      "Populating trees...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\70923\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(344, 10, 159)\n",
      "(344, 5, 159)\n",
      "(344, 225)\n"
     ]
    }
   ],
   "source": [
    "from graph import Graph\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from copy import deepcopy\n",
    "\n",
    "#Convert abundance vector into tree matrix\n",
    "def generate_maps(x, g, f, p=-1):\n",
    "\tid = multiprocessing.Process()._identity\n",
    "\ttemp_g = deepcopy(g)\n",
    "\ttemp_g.populate_graph(f, x)\n",
    "\tmap = temp_g.get_map()\n",
    "\tvector = temp_g.graph_vector_features()\n",
    "\tdel(temp_g)\n",
    "\treturn x, np.array(map), np.array(vector)\n",
    "\n",
    "def generate_dense_maps(x, g, f, p=-1):\n",
    "    id = multiprocessing.Process()._identity\n",
    "    temp_g = deepcopy(g)\n",
    "    temp_g.populate_graph(f, x)\n",
    "    map = temp_g.get_dense_map()\n",
    "    vector = temp_g.graph_vector_features()\n",
    "    del(temp_g)\n",
    "    return np.array(map)\n",
    "\n",
    "print(\"Contsructing tree..\")\n",
    "g = Graph()\n",
    "g.build_graph()\n",
    "g.prune_graph(features_df)\n",
    "print(\"Populating trees...\")\t\n",
    "results1 = Parallel(n_jobs=1)(delayed(generate_maps)(x,g,features_df) for x in filter_X_data.values)\n",
    "x_data_sparse_maps = np.array(np.take(results1,1,1).tolist()) \n",
    "results2 = Parallel(n_jobs=4)(delayed(generate_dense_maps)(x,g,features_df) for x in filter_X_data.values)\n",
    "x_data_dense_maps = np.array(results2) \n",
    "filter_x_data = filter_X_data.values \n",
    "\n",
    "print(x_data_sparse_maps.shape)\n",
    "print(x_data_dense_maps.shape)\n",
    "print(filter_x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10\n",
    "num_test = 10 \n",
    "num_class = len(np.unique(labels))  \n",
    "\n",
    "seed = np.random.randint(100)  \n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(x_data_sparse_maps)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(x_data_dense_maps)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(filter_x_data) \n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "n_values = np.max(labels) + 1\n",
    "labels_oh = np.eye(n_values)[labels]\n",
    "seeds = [8, 16, 32, 64, 128, 256, 1024, 2048, 4096, 8192]  \n",
    "\n",
    "cv_list = [\"Run_\" + str(x) + \"_CV_\" + str(y) for x in range(num_runs) for y in range(num_test)]\n",
    "MetaP_stat_df = pd.DataFrame(index=[\"AUC\", \"ACC\" , \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=cv_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 10 CV\n",
      "################################################## repeat_seed: 8; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 0 , metrics {'ACC': 0.714, 'Recall': 0.714, 'Precision': 0.716, 'F1': 0.713, 'MCC': 0.429, 'AUC': 0.732, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 1 , metrics {'ACC': 0.743, 'Recall': 0.743, 'Precision': 0.749, 'F1': 0.74, 'MCC': 0.49, 'AUC': 0.778, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 2 , metrics {'ACC': 0.771, 'Recall': 0.771, 'Precision': 0.785, 'F1': 0.768, 'MCC': 0.554, 'AUC': 0.869, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 3 , metrics {'ACC': 0.714, 'Recall': 0.714, 'Precision': 0.716, 'F1': 0.713, 'MCC': 0.429, 'AUC': 0.706, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 4 , metrics {'ACC': 0.765, 'Recall': 0.765, 'Precision': 0.802, 'F1': 0.757, 'MCC': 0.566, 'AUC': 0.844, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 5 , metrics {'ACC': 0.765, 'Recall': 0.765, 'Precision': 0.765, 'F1': 0.765, 'MCC': 0.529, 'AUC': 0.827, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 6 , metrics {'ACC': 0.794, 'Recall': 0.794, 'Precision': 0.804, 'F1': 0.793, 'MCC': 0.598, 'AUC': 0.772, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 7 , metrics {'ACC': 0.765, 'Recall': 0.765, 'Precision': 0.768, 'F1': 0.764, 'MCC': 0.533, 'AUC': 0.889, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 8 , metrics {'ACC': 0.794, 'Recall': 0.794, 'Precision': 0.804, 'F1': 0.793, 'MCC': 0.598, 'AUC': 0.785, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 0 ,  fold 9 , metrics {'ACC': 0.676, 'Recall': 0.676, 'Precision': 0.677, 'F1': 0.676, 'MCC': 0.354, 'AUC': 0.699, 'repeat_seed': 8, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 0 , metrics {'ACC': 0.771, 'Recall': 0.771, 'Precision': 0.771, 'F1': 0.771, 'MCC': 0.542, 'AUC': 0.85, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 1 , metrics {'ACC': 0.771, 'Recall': 0.771, 'Precision': 0.785, 'F1': 0.768, 'MCC': 0.554, 'AUC': 0.876, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 2 , metrics {'ACC': 0.771, 'Recall': 0.771, 'Precision': 0.771, 'F1': 0.771, 'MCC': 0.542, 'AUC': 0.807, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 3 , metrics {'ACC': 0.657, 'Recall': 0.657, 'Precision': 0.657, 'F1': 0.657, 'MCC': 0.314, 'AUC': 0.775, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 4 , metrics {'ACC': 0.676, 'Recall': 0.676, 'Precision': 0.677, 'F1': 0.676, 'MCC': 0.354, 'AUC': 0.73, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 5 , metrics {'ACC': 0.588, 'Recall': 0.588, 'Precision': 0.589, 'F1': 0.587, 'MCC': 0.178, 'AUC': 0.682, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 6 , metrics {'ACC': 0.647, 'Recall': 0.647, 'Precision': 0.656, 'F1': 0.642, 'MCC': 0.303, 'AUC': 0.702, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 7 , metrics {'ACC': 0.765, 'Recall': 0.765, 'Precision': 0.768, 'F1': 0.764, 'MCC': 0.533, 'AUC': 0.889, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 8 , metrics {'ACC': 0.706, 'Recall': 0.706, 'Precision': 0.709, 'F1': 0.705, 'MCC': 0.415, 'AUC': 0.747, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 16; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 1 ,  fold 9 , metrics {'ACC': 0.765, 'Recall': 0.765, 'Precision': 0.768, 'F1': 0.764, 'MCC': 0.533, 'AUC': 0.803, 'repeat_seed': 16, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 0 , metrics {'ACC': 0.714, 'Recall': 0.714, 'Precision': 0.714, 'F1': 0.714, 'MCC': 0.428, 'AUC': 0.814, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 1 , metrics {'ACC': 0.829, 'Recall': 0.829, 'Precision': 0.846, 'F1': 0.826, 'MCC': 0.673, 'AUC': 0.886, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 2 , metrics {'ACC': 0.8, 'Recall': 0.8, 'Precision': 0.801, 'F1': 0.8, 'MCC': 0.601, 'AUC': 0.788, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 3 , metrics {'ACC': 0.8, 'Recall': 0.8, 'Precision': 0.801, 'F1': 0.8, 'MCC': 0.6, 'AUC': 0.895, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 4 , metrics {'ACC': 0.941, 'Recall': 0.941, 'Precision': 0.947, 'F1': 0.941, 'MCC': 0.889, 'AUC': 0.931, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 5 , metrics {'ACC': 0.794, 'Recall': 0.794, 'Precision': 0.795, 'F1': 0.794, 'MCC': 0.589, 'AUC': 0.855, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 6 , metrics {'ACC': 0.618, 'Recall': 0.618, 'Precision': 0.618, 'F1': 0.617, 'MCC': 0.236, 'AUC': 0.713, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 7 , metrics {'ACC': 0.588, 'Recall': 0.588, 'Precision': 0.589, 'F1': 0.587, 'MCC': 0.178, 'AUC': 0.633, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 8 , metrics {'ACC': 0.647, 'Recall': 0.647, 'Precision': 0.668, 'F1': 0.636, 'MCC': 0.314, 'AUC': 0.747, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 32; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 2 ,  fold 9 , metrics {'ACC': 0.588, 'Recall': 0.588, 'Precision': 0.588, 'F1': 0.588, 'MCC': 0.176, 'AUC': 0.647, 'repeat_seed': 32, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 0 , metrics {'ACC': 0.6, 'Recall': 0.6, 'Precision': 0.6, 'F1': 0.598, 'MCC': 0.198, 'AUC': 0.696, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 1 , metrics {'ACC': 0.629, 'Recall': 0.629, 'Precision': 0.628, 'F1': 0.628, 'MCC': 0.256, 'AUC': 0.67, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 2 , metrics {'ACC': 0.857, 'Recall': 0.857, 'Precision': 0.867, 'F1': 0.856, 'MCC': 0.723, 'AUC': 0.928, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 3 , metrics {'ACC': 0.657, 'Recall': 0.657, 'Precision': 0.658, 'F1': 0.655, 'MCC': 0.314, 'AUC': 0.745, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 4 , metrics {'ACC': 0.647, 'Recall': 0.647, 'Precision': 0.668, 'F1': 0.636, 'MCC': 0.314, 'AUC': 0.796, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 5 , metrics {'ACC': 0.735, 'Recall': 0.735, 'Precision': 0.783, 'F1': 0.724, 'MCC': 0.516, 'AUC': 0.796, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 6 , metrics {'ACC': 0.735, 'Recall': 0.735, 'Precision': 0.736, 'F1': 0.735, 'MCC': 0.471, 'AUC': 0.761, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 7 , metrics {'ACC': 0.706, 'Recall': 0.706, 'Precision': 0.706, 'F1': 0.706, 'MCC': 0.412, 'AUC': 0.747, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 8 , metrics {'ACC': 0.765, 'Recall': 0.765, 'Precision': 0.765, 'F1': 0.765, 'MCC': 0.529, 'AUC': 0.772, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 64; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 3 ,  fold 9 , metrics {'ACC': 0.765, 'Recall': 0.765, 'Precision': 0.765, 'F1': 0.765, 'MCC': 0.529, 'AUC': 0.834, 'repeat_seed': 64, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 0 , metrics {'ACC': 0.686, 'Recall': 0.686, 'Precision': 0.693, 'F1': 0.684, 'MCC': 0.38, 'AUC': 0.788, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 1 , metrics {'ACC': 0.714, 'Recall': 0.714, 'Precision': 0.74, 'F1': 0.704, 'MCC': 0.45, 'AUC': 0.794, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 2 , metrics {'ACC': 0.686, 'Recall': 0.686, 'Precision': 0.686, 'F1': 0.685, 'MCC': 0.37, 'AUC': 0.732, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 3 , metrics {'ACC': 0.743, 'Recall': 0.743, 'Precision': 0.743, 'F1': 0.742, 'MCC': 0.485, 'AUC': 0.804, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 4 , metrics {'ACC': 0.853, 'Recall': 0.853, 'Precision': 0.854, 'F1': 0.853, 'MCC': 0.707, 'AUC': 0.869, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 5 , metrics {'ACC': 0.794, 'Recall': 0.794, 'Precision': 0.804, 'F1': 0.793, 'MCC': 0.598, 'AUC': 0.848, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 6 , metrics {'ACC': 0.676, 'Recall': 0.676, 'Precision': 0.693, 'F1': 0.669, 'MCC': 0.369, 'AUC': 0.761, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 7 , metrics {'ACC': 0.824, 'Recall': 0.824, 'Precision': 0.828, 'F1': 0.823, 'MCC': 0.652, 'AUC': 0.879, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 8 , metrics {'ACC': 0.706, 'Recall': 0.706, 'Precision': 0.706, 'F1': 0.706, 'MCC': 0.412, 'AUC': 0.772, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 128; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 4 ,  fold 9 , metrics {'ACC': 0.647, 'Recall': 0.647, 'Precision': 0.649, 'F1': 0.646, 'MCC': 0.296, 'AUC': 0.747, 'repeat_seed': 128, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 0 , metrics {'ACC': 0.857, 'Recall': 0.857, 'Precision': 0.858, 'F1': 0.857, 'MCC': 0.715, 'AUC': 0.827, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 1 , metrics {'ACC': 0.743, 'Recall': 0.743, 'Precision': 0.744, 'F1': 0.743, 'MCC': 0.487, 'AUC': 0.889, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 2 , metrics {'ACC': 0.943, 'Recall': 0.943, 'Precision': 0.949, 'F1': 0.943, 'MCC': 0.891, 'AUC': 0.948, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 3 , metrics {'ACC': 0.829, 'Recall': 0.829, 'Precision': 0.832, 'F1': 0.828, 'MCC': 0.66, 'AUC': 0.941, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 4 , metrics {'ACC': 0.706, 'Recall': 0.706, 'Precision': 0.718, 'F1': 0.702, 'MCC': 0.424, 'AUC': 0.699, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 5 , metrics {'ACC': 0.529, 'Recall': 0.529, 'Precision': 0.53, 'F1': 0.528, 'MCC': 0.059, 'AUC': 0.626, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 6 , metrics {'ACC': 0.676, 'Recall': 0.676, 'Precision': 0.682, 'F1': 0.674, 'MCC': 0.359, 'AUC': 0.706, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 7 , metrics {'ACC': 0.647, 'Recall': 0.647, 'Precision': 0.649, 'F1': 0.646, 'MCC': 0.296, 'AUC': 0.699, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 8 , metrics {'ACC': 0.735, 'Recall': 0.735, 'Precision': 0.743, 'F1': 0.733, 'MCC': 0.478, 'AUC': 0.744, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 256; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 5 ,  fold 9 , metrics {'ACC': 0.647, 'Recall': 0.647, 'Precision': 0.647, 'F1': 0.647, 'MCC': 0.294, 'AUC': 0.685, 'repeat_seed': 256, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 0 , metrics {'ACC': 0.686, 'Recall': 0.686, 'Precision': 0.693, 'F1': 0.684, 'MCC': 0.38, 'AUC': 0.716, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 1 , metrics {'ACC': 0.771, 'Recall': 0.771, 'Precision': 0.771, 'F1': 0.771, 'MCC': 0.542, 'AUC': 0.84, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 2 , metrics {'ACC': 0.743, 'Recall': 0.743, 'Precision': 0.749, 'F1': 0.74, 'MCC': 0.49, 'AUC': 0.824, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 3 , metrics {'ACC': 0.686, 'Recall': 0.686, 'Precision': 0.687, 'F1': 0.686, 'MCC': 0.373, 'AUC': 0.712, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 4 , metrics {'ACC': 0.853, 'Recall': 0.853, 'Precision': 0.854, 'F1': 0.853, 'MCC': 0.707, 'AUC': 0.91, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 5 , metrics {'ACC': 0.765, 'Recall': 0.765, 'Precision': 0.78, 'F1': 0.761, 'MCC': 0.545, 'AUC': 0.796, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 6 , metrics {'ACC': 0.824, 'Recall': 0.824, 'Precision': 0.842, 'F1': 0.821, 'MCC': 0.666, 'AUC': 0.896, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 7 , metrics {'ACC': 0.647, 'Recall': 0.647, 'Precision': 0.647, 'F1': 0.647, 'MCC': 0.294, 'AUC': 0.699, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 8 , metrics {'ACC': 0.735, 'Recall': 0.735, 'Precision': 0.736, 'F1': 0.735, 'MCC': 0.471, 'AUC': 0.858, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 1024; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 6 ,  fold 9 , metrics {'ACC': 0.676, 'Recall': 0.676, 'Precision': 0.677, 'F1': 0.676, 'MCC': 0.354, 'AUC': 0.789, 'repeat_seed': 1024, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 0 , metrics {'ACC': 0.771, 'Recall': 0.771, 'Precision': 0.771, 'F1': 0.771, 'MCC': 0.542, 'AUC': 0.791, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 1 , metrics {'ACC': 0.743, 'Recall': 0.743, 'Precision': 0.751, 'F1': 0.742, 'MCC': 0.495, 'AUC': 0.788, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 2 , metrics {'ACC': 0.657, 'Recall': 0.657, 'Precision': 0.658, 'F1': 0.655, 'MCC': 0.314, 'AUC': 0.716, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 3 , metrics {'ACC': 0.8, 'Recall': 0.8, 'Precision': 0.801, 'F1': 0.8, 'MCC': 0.601, 'AUC': 0.889, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 4 , metrics {'ACC': 0.765, 'Recall': 0.765, 'Precision': 0.765, 'F1': 0.765, 'MCC': 0.529, 'AUC': 0.855, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 5 , metrics {'ACC': 0.559, 'Recall': 0.559, 'Precision': 0.559, 'F1': 0.558, 'MCC': 0.118, 'AUC': 0.682, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 6 , metrics {'ACC': 0.618, 'Recall': 0.618, 'Precision': 0.629, 'F1': 0.609, 'MCC': 0.246, 'AUC': 0.727, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 7 , metrics {'ACC': 0.706, 'Recall': 0.706, 'Precision': 0.709, 'F1': 0.705, 'MCC': 0.415, 'AUC': 0.74, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 8 , metrics {'ACC': 0.765, 'Recall': 0.765, 'Precision': 0.765, 'F1': 0.765, 'MCC': 0.529, 'AUC': 0.865, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 2048; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 7 ,  fold 9 , metrics {'ACC': 0.824, 'Recall': 0.824, 'Precision': 0.842, 'F1': 0.821, 'MCC': 0.666, 'AUC': 0.799, 'repeat_seed': 2048, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 0 , metrics {'ACC': 0.743, 'Recall': 0.743, 'Precision': 0.743, 'F1': 0.742, 'MCC': 0.485, 'AUC': 0.765, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 1 , metrics {'ACC': 0.657, 'Recall': 0.657, 'Precision': 0.66, 'F1': 0.657, 'MCC': 0.318, 'AUC': 0.676, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 2 , metrics {'ACC': 0.629, 'Recall': 0.629, 'Precision': 0.631, 'F1': 0.625, 'MCC': 0.257, 'AUC': 0.696, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 3 , metrics {'ACC': 0.571, 'Recall': 0.571, 'Precision': 0.571, 'F1': 0.571, 'MCC': 0.141, 'AUC': 0.693, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 4 , metrics {'ACC': 0.735, 'Recall': 0.735, 'Precision': 0.758, 'F1': 0.729, 'MCC': 0.492, 'AUC': 0.882, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 5 , metrics {'ACC': 0.735, 'Recall': 0.735, 'Precision': 0.758, 'F1': 0.729, 'MCC': 0.492, 'AUC': 0.799, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 6 , metrics {'ACC': 0.824, 'Recall': 0.824, 'Precision': 0.842, 'F1': 0.821, 'MCC': 0.666, 'AUC': 0.851, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 7 , metrics {'ACC': 0.765, 'Recall': 0.765, 'Precision': 0.768, 'F1': 0.764, 'MCC': 0.533, 'AUC': 0.789, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 8 , metrics {'ACC': 0.735, 'Recall': 0.735, 'Precision': 0.736, 'F1': 0.735, 'MCC': 0.471, 'AUC': 0.858, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 4096; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 8 ,  fold 9 , metrics {'ACC': 0.647, 'Recall': 0.647, 'Precision': 0.647, 'F1': 0.647, 'MCC': 0.294, 'AUC': 0.779, 'repeat_seed': 4096, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_00 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 0 , metrics {'ACC': 0.629, 'Recall': 0.629, 'Precision': 0.628, 'F1': 0.628, 'MCC': 0.256, 'AUC': 0.67, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_01 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 1 , metrics {'ACC': 0.571, 'Recall': 0.571, 'Precision': 0.572, 'F1': 0.571, 'MCC': 0.144, 'AUC': 0.654, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_02 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 2 , metrics {'ACC': 0.743, 'Recall': 0.743, 'Precision': 0.744, 'F1': 0.743, 'MCC': 0.487, 'AUC': 0.794, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_03 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 3 , metrics {'ACC': 0.686, 'Recall': 0.686, 'Precision': 0.7, 'F1': 0.678, 'MCC': 0.382, 'AUC': 0.719, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_04 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 4 , metrics {'ACC': 0.765, 'Recall': 0.765, 'Precision': 0.768, 'F1': 0.764, 'MCC': 0.533, 'AUC': 0.869, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_05 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 5 , metrics {'ACC': 0.824, 'Recall': 0.824, 'Precision': 0.842, 'F1': 0.821, 'MCC': 0.666, 'AUC': 0.844, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_06 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 6 , metrics {'ACC': 0.676, 'Recall': 0.676, 'Precision': 0.682, 'F1': 0.674, 'MCC': 0.359, 'AUC': 0.768, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_07 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 7 , metrics {'ACC': 0.676, 'Recall': 0.676, 'Precision': 0.693, 'F1': 0.669, 'MCC': 0.369, 'AUC': 0.765, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_08 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 8 , metrics {'ACC': 0.735, 'Recall': 0.735, 'Precision': 0.758, 'F1': 0.729, 'MCC': 0.492, 'AUC': 0.82, 'repeat_seed': 8192, 'method': 'Meta_P'}\n",
      "################################################## repeat_seed: 8192; fold_09 ##################################################\n",
      "training........ Micro Permutator model ................. \n",
      "MetaP run 9 ,  fold 9 , metrics {'ACC': 0.765, 'Recall': 0.765, 'Precision': 0.78, 'F1': 0.761, 'MCC': 0.545, 'AUC': 0.841, 'repeat_seed': 8192, 'method': 'Meta_P'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score ,accuracy_score , matthews_corrcoef, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from MetaP import MetaP  \n",
    "import torch \n",
    "\n",
    "print(\"Starting 10 CV\")\n",
    "for i , repeat_seed in enumerate(seeds) : \n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=repeat_seed)\n",
    "    skf_index = skf.split(x_data_dense_maps, labels) \n",
    "    \n",
    "    for j , idx in enumerate(skf_index) :\n",
    "        fold_num = \"fold_%s\" % str(j).zfill(2)\n",
    "        print('#'*50 + ' repeat_seed: %s; %s ' % (repeat_seed, fold_num) + '#'*50 )\n",
    "\n",
    "        train_index, test_index = idx    \n",
    "        # train_x, test_x = x_data_sparse_maps[train_index], x_data_sparse_maps[test_index]\n",
    "        \n",
    "        train_x, test_x = x_data_dense_maps[train_index], x_data_dense_maps[test_index]\n",
    "        #train_y, test_y = labels_oh[train_index], labels_oh[test_index]\n",
    "        train_y, test_y = labels[train_index], labels[test_index]\n",
    "\n",
    "        tree_row = train_x.shape[1]\n",
    "        tree_col = train_x.shape[2]\n",
    "        scaler = MinMaxScaler().fit(train_x.reshape(-1, tree_row * tree_col))\n",
    "        train_x = np.clip(scaler.transform(train_x.reshape(-1, tree_row * tree_col)), 0, 1).reshape(-1, tree_row, tree_col)\n",
    "        test_x = np.clip(scaler.transform(test_x.reshape(-1, tree_row * tree_col)), 0, 1).reshape(-1, tree_row, tree_col)\n",
    "\n",
    "        class DatasetLoarder(Dataset) :\n",
    "            def __init__(self , X_train , y_train) :\n",
    "                self.len = X_train.shape[0]\n",
    "                self.x_data = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "                self.y_data = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "                \n",
    "            def __getitem__(self , index) :\n",
    "                return self.x_data[index] , self.y_data[index]\n",
    "\n",
    "            def __len__(self) :\n",
    "                return self.len \n",
    "\n",
    "        train_dataset  = DatasetLoarder(train_x , train_y)  \n",
    "        train_loader = DataLoader(dataset=train_dataset , batch_size=32 , num_workers=0) # num_workers 线程并行数\n",
    "        test_dataset = DatasetLoarder(test_x , test_y)\n",
    "        test_loader = DataLoader(dataset=test_dataset , batch_size=32 , num_workers=0 ) # num_workers 线程并行数\n",
    "                \n",
    "                \n",
    "        def eval(model , test_loader): # test\n",
    "            # loss function\n",
    "            #criterion = torch.nn.CrossEntropyLoss()\n",
    "            model.eval()\n",
    "            true_label = [] \n",
    "            y_prob = []\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for step , batch in enumerate(test_loader):\n",
    "                    x, label = batch\n",
    "                    \n",
    "                    val_output = model(x)\n",
    "                    #val_loss = criterion(val_output, label)\n",
    "                    \n",
    "                    true_label  = true_label + label.tolist() \n",
    "                    y_prob = y_prob + val_output.tolist()\n",
    "                    \n",
    "            y_prob = np.array(y_prob)\n",
    "            true_label = np.array(true_label)\n",
    "            return true_label , y_prob \n",
    "\n",
    "        def train(model , train_loader , test_loader , learn_rate , epoch ) :\n",
    "            \n",
    "            # loss function\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "            # optimizer\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate ) # 2e-4 \n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5 , gamma=0.5)\n",
    "            \n",
    "            for i in range(epoch):\n",
    "                model.train()\n",
    "                # one epoch\n",
    "                for step, batch in enumerate(train_loader):\n",
    "                    x, label = batch\n",
    "                    output = model(x)\n",
    "                    loss = criterion(output, label)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                scheduler.step()\n",
    "                # y_true , y_prob  = eval(model=model , test_loader=test_loader_species) \n",
    "                # y_pred = np.argmax(y_prob , axis=1)\n",
    "                # #print(\"method = {}  test Epoch:{} ,   eval_acc:{} , eval_auc :{} \".format(method , i, round(accuracy_score(y_true, y_pred), 3) , round(roc_auc_score(y_true, y_prob, multi_class='ovo'), 3)))\n",
    "                # print(\"method = {}  test Epoch:{} ,  eval_acc:{} \".format(method , i, round(accuracy_score(y_true, y_pred), 3)))\n",
    "\n",
    "                 \n",
    "        model = MetaP(\n",
    "            image_h= train_x.shape[1],\n",
    "            image_w= train_x.shape[2],\n",
    "            segments = 8,\n",
    "            patch_h = train_x.shape[1] ,\n",
    "            patch_w = 3 ,\n",
    "            dim = 48,\n",
    "            depth = 1,\n",
    "            num_classes = 2 ,\n",
    "            expansion_factor = 1, \n",
    "        )\n",
    "        print(\"training........ Micro Permutator model ................. \")\n",
    "\n",
    "        train(model  , train_loader , test_loader , learn_rate=5e-4 , epoch=20)\n",
    "        \n",
    "        y_true , y_prob  = eval(model=model , test_loader=test_loader) \n",
    "        y_pred = np.argmax(y_prob , axis=1)\n",
    "       \n",
    "       \n",
    "        metrics = {   \n",
    "            \"ACC\" : round(accuracy_score(y_true, y_pred), 3),\n",
    "            \"Recall\" : round(recall_score(y_true, y_pred , average='weighted') , 3 ) ,\n",
    "            \"Precision\" : round(precision_score(y_true, y_pred, average='weighted') , 3) ,\n",
    "            \"F1\"    : round(f1_score(y_true, y_pred, average='weighted') , 3) , \n",
    "            \"MCC\" : round(matthews_corrcoef(y_true, y_pred), 3),\n",
    "            \"AUC\" : round(roc_auc_score(y_true, y_prob[:, 1]) , 3) ,\n",
    "            \"repeat_seed\" : repeat_seed ,  \n",
    "            \"method\" : \"Meta_P\",\n",
    "            } \n",
    "        \n",
    "        print(\"MetaP run {} ,  fold {} , metrics {}\".format(i , j , metrics))\n",
    "\n",
    "        MetaP_stat_df.loc[\"AUC\"][\"Run_\" + str(i) + \"_CV_\" + str(j)] = metrics[\"AUC\"]\n",
    "        MetaP_stat_df.loc[\"ACC\"][\"Run_\" + str(i) + \"_CV_\" + str(j)] = metrics[\"ACC\"]\n",
    "        MetaP_stat_df.loc[\"MCC\"][\"Run_\" + str(i) + \"_CV_\" + str(j)] = metrics[\"MCC\"]\n",
    "        MetaP_stat_df.loc[\"Precision\"][\"Run_\" + str(i) + \"_CV_\" + str(j)] =  metrics[\"Precision\"]\n",
    "        MetaP_stat_df.loc[\"Recall\"][\"Run_\" + str(i) + \"_CV_\" + str(j)]= metrics[\"Recall\"]\n",
    "        MetaP_stat_df.loc[\"F1\"][\"Run_\" + str(i) + \"_CV_\" + str(j)] =  metrics[\"F1\"] \n",
    "\n",
    "        del(model) \n",
    "    #     break\n",
    "    # break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC          0.78598\n",
      "ACC          0.72379\n",
      "MCC          0.45335\n",
      "Precision    0.72995\n",
      "Recall       0.72379\n",
      "F1           0.72187\n",
      "dtype: float64\n",
      "AUC          0.076265\n",
      "ACC          0.080058\n",
      "MCC          0.161878\n",
      "Precision    0.082103\n",
      "Recall       0.080058\n",
      "F1           0.080462\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# results_dir = \"./results/\" + disease\n",
    "# MetaP_stat_df.to_csv(results_dir + \"/MetaP_Half_W_ALL_result.csv\")\n",
    "# MetaP_stat_df.mean(1).to_csv(results_dir + \"/MetaP_Half_W_evaluation.csv\")\n",
    "# MetaP_stat_df.std(1).to_csv(results_dir + \"/MetaP_Half_W_evaluation.csv\", mode='a') \n",
    "print(MetaP_stat_df.mean(1))\n",
    "print(MetaP_stat_df.std(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1976153ee4400fa378d70e78b886b43c01301f7b206e70b97b5161f60de6d8c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
